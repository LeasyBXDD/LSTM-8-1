{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T11:42:35.696795Z",
     "start_time": "2024-08-05T11:42:35.688023Z"
    }
   },
   "cell_type": "code",
   "source": "# %pip install numpy tensorflow",
   "id": "1bdf52e18e7b688a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-05T11:42:36.113972Z",
     "start_time": "2024-08-05T11:42:35.725509Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Attention, Concatenate\n",
    "\n",
    "# 定义输入特征数和类别数\n",
    "num_features = 30\n",
    "num_classes = 10 \n",
    "\n",
    "# 定义输入层\n",
    "sequence_input = Input(shape=(None, num_features), dtype='float32')\n",
    "\n",
    "# 双向LSTM层\n",
    "lstm_out = Bidirectional(LSTM(64, return_sequences=True))(sequence_input)\n",
    "\n",
    "# 注意力机制\n",
    "attention = Attention()([lstm_out, lstm_out])\n",
    "context_vector = Concatenate()([lstm_out, attention])\n",
    "\n",
    "# 输出层\n",
    "output = Dense(num_classes, activation='softmax')(context_vector)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 输出模型结构\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, None, 30)]           0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirecti  (None, None, 128)            48640     ['input_2[0][0]']             \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, None, 128)            0         ['bidirectional_1[0][0]',     \n",
      "                                                                     'bidirectional_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, None, 256)            0         ['bidirectional_1[0][0]',     \n",
      " )                                                                   'attention_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 10)             2570      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51210 (200.04 KB)\n",
      "Trainable params: 51210 (200.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:11:51.007565Z",
     "start_time": "2024-08-05T12:11:50.670042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Attention, Concatenate, TimeDistributed\n",
    "\n",
    "# 定义输入特征数和类别数\n",
    "num_features = 30\n",
    "num_classes = 10 \n",
    "\n",
    "# 定义输入层\n",
    "sequence_input = Input(shape=(None, num_features), dtype='float32')\n",
    "\n",
    "# 双向LSTM层\n",
    "lstm_out = Bidirectional(LSTM(64, return_sequences=True))(sequence_input)\n",
    "\n",
    "# 注意力机制\n",
    "attention = Attention()([lstm_out, lstm_out])\n",
    "\n",
    "# 连接Bi-LSTM的输出和注意力的输出\n",
    "context_vector = Concatenate(axis=-1)([lstm_out, attention])\n",
    "\n",
    "# 全连接层\n",
    "dense_output = TimeDistributed(Dense(num_classes))(context_vector)\n",
    "\n",
    "# Softmax层\n",
    "output = tf.keras.layers.Softmax()(dense_output)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=sequence_input, outputs=output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 输出模型结构\n",
    "model.summary()\n"
   ],
   "id": "13b93b26fd61ab2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, None, 30)]           0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirecti  (None, None, 128)            48640     ['input_3[0][0]']             \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, None, 128)            0         ['bidirectional_2[0][0]',     \n",
      "                                                                     'bidirectional_2[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, None, 256)            0         ['bidirectional_2[0][0]',     \n",
      " )                                                                   'attention_2[0][0]']         \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, None, 10)             2570      ['concatenate_2[0][0]']       \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " softmax (Softmax)           (None, None, 10)             0         ['time_distributed[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51210 (200.04 KB)\n",
      "Trainable params: 51210 (200.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:23:31.247922Z",
     "start_time": "2024-08-05T12:23:30.916462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dense, Attention, Concatenate, TimeDistributed, Lambda\n",
    "\n",
    "# 定义输入特征数和类别数\n",
    "num_features = 30 \n",
    "num_classes = 10 \n",
    "\n",
    "# 定义输入层\n",
    "sequence_input = Input(shape=(None, num_features), dtype='float32')\n",
    "\n",
    "# 双向LSTM层\n",
    "lstm_out = Bidirectional(LSTM(64, return_sequences=True))(sequence_input)\n",
    "\n",
    "# 注意力机制\n",
    "attention = Attention()([lstm_out, lstm_out])\n",
    "\n",
    "# 连接Bi-LSTM的输出和注意力的输出\n",
    "context_vector = Concatenate(axis=-1)([lstm_out, attention])\n",
    "\n",
    "# 全连接层 + Softmax 层\n",
    "# 将加权求和结果输入到全连接层进行维度转换\n",
    "dense_output = TimeDistributed(Dense(num_classes))(context_vector)\n",
    "\n",
    "# 使用 softmax 函数归一化\n",
    "output = tf.keras.layers.Softmax()(dense_output)\n",
    "\n",
    "# 获取 t+1 时间步的输出\n",
    "# t+1 时间步是输入的最后一个时间步，所以我们取最后一个时间步的预测\n",
    "final_output = Lambda(lambda x: x[:, -1, :])(output)\n",
    "\n",
    "# 定义模型\n",
    "model = Model(inputs=sequence_input, outputs=final_output)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 输出模型结构\n",
    "model.summary()\n"
   ],
   "id": "1d4be978951994ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, None, 30)]           0         []                            \n",
      "                                                                                                  \n",
      " bidirectional_3 (Bidirecti  (None, None, 128)            48640     ['input_4[0][0]']             \n",
      " onal)                                                                                            \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, None, 128)            0         ['bidirectional_3[0][0]',     \n",
      "                                                                     'bidirectional_3[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, None, 256)            0         ['bidirectional_3[0][0]',     \n",
      " )                                                                   'attention_3[0][0]']         \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, None, 10)             2570      ['concatenate_3[0][0]']       \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " softmax_1 (Softmax)         (None, None, 10)             0         ['time_distributed_1[0][0]']  \n",
      "                                                                                                  \n",
      " lambda (Lambda)             (None, 10)                   0         ['softmax_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 51210 (200.04 KB)\n",
      "Trainable params: 51210 (200.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 测试",
   "id": "e11ef544e85c12e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-05T12:31:29.015484Z",
     "start_time": "2024-08-05T12:31:28.946344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 定义输入特征数和类别数\n",
    "num_features = 30 \n",
    "num_classes = 10 \n",
    "\n",
    "# 生成测试数据\n",
    "# 生成一批序列，每个序列有不同的长度，每个时间步有num_features个特征\n",
    "batch_size = 5\n",
    "sequence_length = 15  # 假设每个序列的长度为15\n",
    "X_test = np.random.random((batch_size, sequence_length, num_features))\n",
    "\n",
    "print(\"Test data shape:\", X_test.shape)\n",
    "# print(X_test)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# 打印预测结果\n",
    "# print(\"Predictions shape:\", predictions.shape)\n",
    "print(\"Predictions:\", predictions) # 活动概率分布 APD\n"
   ],
   "id": "291d0d18cc1913fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.42447092 0.24251966 0.67116598 ... 0.88051141 0.04932014 0.16036292]\n",
      "  [0.46959367 0.93995296 0.81272675 ... 0.11763351 0.2473363  0.48661646]\n",
      "  [0.60997488 0.31920114 0.89980062 ... 0.50193722 0.36517503 0.17928614]\n",
      "  ...\n",
      "  [0.61680108 0.55919483 0.2541663  ... 0.69023282 0.53553673 0.89482918]\n",
      "  [0.28380233 0.50723815 0.7479413  ... 0.76256672 0.0172974  0.13241657]\n",
      "  [0.14858227 0.04735218 0.33282684 ... 0.63022875 0.11150046 0.40315685]]\n",
      "\n",
      " [[0.81350712 0.05545562 0.71089439 ... 0.284262   0.56763787 0.98231231]\n",
      "  [0.64421447 0.85206319 0.96900237 ... 0.60178744 0.23497083 0.47474367]\n",
      "  [0.62308567 0.18881142 0.4013341  ... 0.5295352  0.30591888 0.72310612]\n",
      "  ...\n",
      "  [0.58090372 0.81816376 0.63868628 ... 0.67712883 0.09745508 0.99328394]\n",
      "  [0.5053864  0.18124221 0.91120007 ... 0.78043068 0.30582116 0.53904417]\n",
      "  [0.35974551 0.56960027 0.38458789 ... 0.19228921 0.05731467 0.51107426]]\n",
      "\n",
      " [[0.16754048 0.30241849 0.62300648 ... 0.01542437 0.07918195 0.37983646]\n",
      "  [0.65979025 0.31248649 0.05285254 ... 0.60337996 0.83408767 0.29253802]\n",
      "  [0.1144828  0.25885112 0.4205557  ... 0.20841372 0.67533885 0.40212057]\n",
      "  ...\n",
      "  [0.65400336 0.61823318 0.53984228 ... 0.16768122 0.57467675 0.36690293]\n",
      "  [0.77799084 0.21201899 0.49765408 ... 0.70501131 0.68098463 0.47584916]\n",
      "  [0.59203862 0.3867366  0.22378728 ... 0.89633018 0.34348597 0.197921  ]]\n",
      "\n",
      " [[0.76122518 0.37182839 0.10620764 ... 0.48516277 0.34535793 0.69744923]\n",
      "  [0.19115707 0.72313969 0.40497309 ... 0.77314056 0.26211135 0.09128666]\n",
      "  [0.54715698 0.66638874 0.0236993  ... 0.50483375 0.16029614 0.71966662]\n",
      "  ...\n",
      "  [0.79345704 0.09007873 0.83441837 ... 0.99345753 0.90170061 0.04068709]\n",
      "  [0.65936764 0.96259957 0.65047763 ... 0.27178924 0.79142611 0.45049717]\n",
      "  [0.64875483 0.73123396 0.20233207 ... 0.82242471 0.54968157 0.39396804]]\n",
      "\n",
      " [[0.11047323 0.85879308 0.13691277 ... 0.97166203 0.82792257 0.21457985]\n",
      "  [0.23873583 0.66466244 0.81955296 ... 0.55670577 0.11421734 0.15287299]\n",
      "  [0.501279   0.80891663 0.42382773 ... 0.95786007 0.583579   0.16426544]\n",
      "  ...\n",
      "  [0.28371554 0.98331728 0.01248876 ... 0.6905643  0.39474505 0.35888264]\n",
      "  [0.2476397  0.01573621 0.71362014 ... 0.97482282 0.06577363 0.37499333]\n",
      "  [0.60286456 0.75911359 0.89573178 ... 0.5996443  0.82596756 0.8421403 ]]]\n",
      "Test data shape: (5, 15, 30)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predictions: [[0.13285595 0.12058014 0.11009065 0.09062983 0.10000502 0.09106693\n",
      "  0.07572963 0.08831669 0.0964244  0.09430069]\n",
      " [0.12677142 0.12245585 0.11413992 0.09182809 0.10185262 0.08286092\n",
      "  0.07627153 0.09506682 0.09128748 0.09746535]\n",
      " [0.12726077 0.11677918 0.11130319 0.08822682 0.09852243 0.09274585\n",
      "  0.07372873 0.09582656 0.10420051 0.0914059 ]\n",
      " [0.13305232 0.10916682 0.11132156 0.09815332 0.10001214 0.08971812\n",
      "  0.08144515 0.08539597 0.10577627 0.0859583 ]\n",
      " [0.12638742 0.11342251 0.11692761 0.10071971 0.09975225 0.09268341\n",
      "  0.07816704 0.08683857 0.09814042 0.08696108]]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 详细步骤说明\n",
    "\n",
    "1. **输入层**：我们假设输入数据已经被预处理为形状为 `(batch_size, sequence_length, num_features)` 的张量，其中 `num_features` 是每个时间步的特征数。\n",
    "\n",
    "2. **Bi-LSTM层**：使用 `Bidirectional` 包装 `LSTM` 层，并设置 `return_sequences=True` 以确保输出每个时间步的输出。\n",
    "\n",
    "3. **注意力层**：引入注意力机制，通过计算每个时间步的隐态输出之间的相似度系数得到注意力权重，然后与隐态向量加权求和得到注意力上下文。\n",
    "\n",
    "4. **输出层**：通过全连接层和 Softmax 函数，将模型输出转换为下一个时间步的活动概率分布。"
   ],
   "id": "544b0f8670eb2070"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
